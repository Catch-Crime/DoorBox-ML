import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import transforms, datasets
from torchvision.transforms import InterpolationMode
from face_rotation import AlignAndCropFace
from PIL import Image

def get_data_loaders(
    train_dir: str,
    test_dir: str,
    image_size=(320, 320),
    batch_size=32,
    num_workers=0,
    pin_memory=True
):
    I = InterpolationMode
    w, h = image_size

    align = AlignAndCropFace(out_size=image_size, enlarge=1.3, fill=(128, 128, 128))

    # 320 320으로 고정
    force_resize_pil = transforms.Lambda(
        lambda img: img.resize((w, h), Image.BICUBIC) if isinstance(img, Image.Image) else img
    )

    # Train Transform (회전 강화)
    train_transform = transforms.Compose([
        align,
        transforms.Resize((336, 336), interpolation=I.BICUBIC),
        transforms.RandomAffine(
            degrees=25, translate=(0.06, 0.06), scale=(0.9, 1.1),
            shear=(-8, 8, -5, 5),
            interpolation=I.BICUBIC
        ),
        transforms.RandomPerspective(distortion_scale=0.2, p=0.3, interpolation=I.BICUBIC),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.CenterCrop((320, 320)),
        force_resize_pil,
        transforms.ColorJitter(brightness=0.25, contrast=0.25),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225]),
    ])

    # Test Transform
    test_transform = transforms.Compose([
        align,
        force_resize_pil,
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225]),
    ])

    train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)
    test_dataset  = datasets.ImageFolder(test_dir,  transform=test_transform)

    # Robust Collate
    def robust_collate(batch):
        # None/깨진 샘플 제거
        batch = [(x, y) for (x, y) in batch if x is not None]
        if len(batch) == 0:
            return torch.empty(0), torch.empty(0, dtype=torch.long)

        imgs, ys = [], []
        for img, y in batch:
            if not torch.is_tensor(img):
                if isinstance(img, Image.Image):
                    img = transforms.ToTensor()(img)
                else:
                    continue
            if img.dim() != 3:
                continue

            C, H, W = img.shape
            if H != h or W != w:
                img = img.unsqueeze(0)
                img = F.interpolate(img, size=(h, w), mode="bilinear", align_corners=False)
                img = img.squeeze(0)
            imgs.append(img)
            ys.append(y)

        if len(imgs) == 0:
            return torch.empty(0), torch.empty(0, dtype=torch.long)

        return torch.stack(imgs, 0), torch.tensor(ys, dtype=torch.long)

    # DataLoader
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
        persistent_workers=(num_workers > 0),
        collate_fn=robust_collate
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory,
        persistent_workers=(num_workers > 0),
        collate_fn=robust_collate
    )

    return train_loader, test_loader
